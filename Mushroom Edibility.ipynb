{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d606d-8eb6-4718-b825-303b5624f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f9687-28b2-48d0-8993-56daeef3a920",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2433bbb-3dfa-47c8-ae77-6c6f39e73581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    '''\n",
    "    - encodes all variables (using drop_first)\n",
    "    - also where I drop features to explore predictive power of limited feature sets \n",
    "    '''\n",
    "    X = df.drop(['class'], axis=1)\n",
    "    # drop the most predictive featuers\n",
    "    # X = df.drop(['class', 'odor','gill-size','bruises', 'ring-type', 'stalk-surface-above-ring', 'spore-print-color', 'population', 'stalk-surface-below-ring',], axis=1)\n",
    "    # drop just odor \n",
    "    # X = df.drop(['class','odor'], axis=1)\n",
    "    # use only the least predictive features\n",
    "    # X = df[[\"cap-shape\", \"veil-color\", \"cap-surface\",\"stalk-color-above-ring\", \"gill-color\", \"cap-color\"]]\n",
    "    # use only odor\n",
    "    # X = df[\"odor\"]\n",
    "    y = df['class'].map({'e':0,'p':1})\n",
    "\n",
    "    encoded_X = pd.get_dummies(X, drop_first=True).astype(int)\n",
    "    \n",
    "    # Add target back\n",
    "    encoded_df = encoded_X.copy()\n",
    "    encoded_df['class'] = y\n",
    "    return encoded_df, encoded_df.drop('class', axis=1), encoded_df['class']\n",
    "\n",
    "def match_columns(train_X, other_X):\n",
    "    '''\n",
    "    ensures test/validation data has all the columns that training data has\n",
    "    (it's ok if they have extras, but they need at least the training data ones)\n",
    "    '''\n",
    "    for col in train_X.columns:\n",
    "        if col not in other_X.columns:\n",
    "            other_X[col] = 0  \n",
    "    return other_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd5add-1f16-42b9-aec9-7132a854284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8cea-0d7b-4bf5-b69e-3f54903cd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, stratify=data['class'], random_state = 9292, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=.5, stratify=temp_df['class'], random_state = 1, shuffle=True)\n",
    "\n",
    "# encode each dataset\n",
    "encoded_train, train_X, train_y = encode_data(train_df)\n",
    "encoded_val, val_X, val_y = encode_data(val_df)\n",
    "encoded_test, test_X, test_y = encode_data(test_df)\n",
    "\n",
    "# match the training columns in val and test data \n",
    "val_X = match_columns(train_X, val_X)\n",
    "test_X = match_columns(train_X, test_X)\n",
    "\n",
    "# sort all columns the same way\n",
    "val_X = val_X.sort_index(axis=1)\n",
    "test_X = test_X.sort_index(axis=1)\n",
    "train_X = train_X.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683e659-f2b1-4617-81fe-693d7b0d8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32f67f-7507-40b9-8807-c38fb9897c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192b131-cd1f-4798-bd61-a2d63068004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize how each feature contributes to poisonous/edible \n",
    "# batch size is used for readablility (puts batch_size variables on the same chart)\n",
    "\n",
    "batch_size = 6\n",
    "# Get list of column names excluding 'class'\n",
    "feature_cols = [col for col in encoded_train.columns if col != 'class']\n",
    "n_batches = (len(feature_cols) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(n_batches):\n",
    "    # Slice the list of column names instead of the DataFrame\n",
    "    batch_cols = feature_cols[i*batch_size : (i+1)*batch_size]\n",
    "    counts = []\n",
    "    \n",
    "    for col in batch_cols:\n",
    "        poison_count = encoded_train[encoded_train['class'] == 1][col].sum()\n",
    "        edible_count = encoded_train[encoded_train['class'] == 0][col].sum()\n",
    "        counts.append([col, poison_count, edible_count])\n",
    "    \n",
    "    count_df = pd.DataFrame(counts, columns=['feature', 'poison', 'edible'])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    count_df.plot(x='feature', y=['poison', 'edible'], kind='bar')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(f'Feature Counts by Class (Batch {i+1} of {n_batches})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8b83b-e036-4362-bd91-341b30f7dc18",
   "metadata": {},
   "source": [
    "# Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b38b6-a51a-4057-8516-a8ba86619464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model \n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  \n",
    "    max_depth=None,    \n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=103\n",
    ")\n",
    "\n",
    "# train it\n",
    "rf_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbd7b3-d78d-4747-96e2-d5fa8487b91b",
   "metadata": {},
   "source": [
    "# Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba66167-3c62-4a32-ad35-144130eea97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate it\n",
    "y_pred = rf_model.predict(val_X)\n",
    "print(classification_report(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a53b6-f043-4440-9763-80a118372d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine most (or least if you flip the ranking) important features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': train_X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6abc9a-dd9a-4475-954e-0b7c4876d7f3",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959c0b3-5bf0-446d-87b4-dbb1e1ee9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rf_model.predict(test_X)\n",
    "print(classification_report(test_y, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mushroomenv)",
   "language": "python",
   "name": ".mushroomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
